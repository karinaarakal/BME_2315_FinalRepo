{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d08828-39be-453d-9c15-7d0737ceb72f",
   "metadata": {},
   "source": [
    "## Module 4: ODEs and Disease\n",
    "\n",
    "## Team Members:\n",
    "Will Rousseau and Karina Arakal\n",
    "## Project Title:\n",
    "Module 4, Group 2: Ebola Projections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8372d796-186a-4ae2-9b4f-0065979e555a",
   "metadata": {},
   "source": [
    "## Project Goal:\n",
    "This project seeks to fit the SIR model to real-world data of infections over time for the 2014 Ebola outbreak in Sierra Leone. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91408b75-185a-4d66-9ce7-7c7aabbde5e1",
   "metadata": {},
   "source": [
    "## Disease Background:\n",
    "\n",
    "Using your assigned disease, fill in the following bullet points. \n",
    "\n",
    "* Prevalence & incidence\n",
    "\n",
    "The Western African Ebola virus epidemic (2013–2016) was the most widespread outbreak of Ebola virus disease (EVD) in history. Causing major loss of life and socioeconomic disruption in the region, mainly in Guinea, Liberia, and Sierra Leone. The first cases were recorded in Guinea in December 2013; Later, the disease spread to neighboring Liberia and Sierra Leone, with minor outbreaks occurring elsewhere. It caused significant mortality, with the case fatality rate reported which was initially considered, while the rate among hospitalized patients was 57–59%. The final numbers 28,616 people, including 11,310 deaths, for a case-fatality rate of 40%.\n",
    "* Economic burden\n",
    "\n",
    "The Western Aftern Ebola outbreak has an estimated economic impact of 2.8 - 53 billion dollars, primarly accounting for lost GDP, direct healthcare costs, lost productivity from sickness and fear, and a widespread disruption in agriculture, trade, and tourism. \n",
    "* Risk factors (genetic, lifestyle) & Societal determinants\n",
    "\n",
    "Ebola risk factors include direct contact with the blood, bodily fluids, or organs of an infected person or animal, especially during funeral or burial sites. High-risk groups include healcare workers, individuals involved in burial riturals, family members caring for a sick person, and others who handle contaminated objects.  \n",
    "* Symptoms\n",
    "\n",
    "Symptoms include fever, aches, pains, and fatigue early in the illness. Later on, symptoms may include diarrhea, vomiting, and unexplained bleeding. Average symptoms begin, on average, 8-10 days after exposure. During the terminal stage of the disease, there is an increase in vascular permeability, massive tissue injury, dysregulation of the coagulation cascade, and hemorrhage\n",
    "* Diagnosis\n",
    "\n",
    "Healthcare providers use a PCR test to they test for orthoebolavirus antibodies. \n",
    "* Biological mechanisms (anatomy, organ physiology, cell & molecular physiology)\n",
    "\n",
    "Ebola disease is caused by an infection with an orthoebolavirus. Orthoebolaviruses are found primarily in sub-Saharan Africa. The virus enters the cell through receptor-mediated endocytosis and creates negative-sense genomes and viral proteins. Ebola virus initially and preferentially infects monocytes, macrophages, and DCs. Infection of DCs impairs their maturation and suppresses type I IFN responses, thereby preventing T cell activation. Infection of monocytes and macrophages leads to the robust expression of inflammatory mediators. Eventually, the inflammatory cytokines are responsible for vascular leakage. EBOV systemically disseminates to liver, kidneys, adrenal glands, and endothelial cells, which contributes to symptoms associated with hemorrhagic fever."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b99aefb-cb03-4bd8-b972-437eb0e02dfe",
   "metadata": {},
   "source": [
    "## Dataset: \n",
    "\n",
    "The data set tracks cumulative confirmed, probable, and suspected Ebola cases from 8/29/2014 to 12/29/2015 in Sierra Leone. Sierra Leone was one of the neighboring countries of the original outbreak in Guinea. This dataset was created by Devakumar K.P 5 years ago: https://www.kaggle.com/datasets/imdevskp/ebola-outbreak-20142016-complete-dataset. This data was extracted from the World Health Organization database. It was measured by # of cumulative cases along a 2 year timeline. \n",
    "\n",
    "The following code reads in the csv file of cumulative cases of Ebola in Sierra Leone and plots infections and recoveries over time. Since I and R are dwarfed by the population of Sierra Leone (S), the susceptible population is not plotted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e0baf",
   "metadata": {},
   "source": [
    "## Data Analyis: \n",
    "\n",
    "### Methods\n",
    "\n",
    "First, we fit an SIR model to our data using Euler's method. Next, we predict the second half of our data using only the first half as an input into our Euler's SIR model, and compare that to the RK4 method. FInally, we attempt to optimize our model with a time-dependent parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420d8a70",
   "metadata": {},
   "source": [
    "#### 1. Fitting the SIR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb887f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_functions import convert_cumulative_to_SIR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Load the EBOLA dataset\n",
    "data = pd.read_csv(r\"ebola_sierra_leone_data_2014_2015_cumulative.csv\")\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "print(\"\\nColumns:\", data.columns.tolist())\n",
    "\n",
    "# Preprocess data\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data = data.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Plot the confirmed cases over time for the whole dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data['date'],\n",
    "         data['confirmed_cases'],\n",
    "         label='Confirmed Cases',\n",
    "         marker=\"o\")\n",
    "plt.ylim(0, 15000)\n",
    "plt.xlabel('Date')\n",
    "plt.xlim(pd.Timestamp('2014-08-29'), pd.Timestamp('2015-12-29'))\n",
    "plt.ylabel('Number of Cases')\n",
    "plt.title('Sierra Leone Ebola Confirmed Cases Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate new cases each day\n",
    "data['new_cases'] = data['confirmed_cases'].diff().fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data['date'],\n",
    "         data['new_cases'],\n",
    "         label='New Confirmed Cases',\n",
    "         marker=\"o\",\n",
    "         markersize=3)\n",
    "plt.xlabel('Date')\n",
    "plt.xlim(pd.Timestamp('2014-08-29'), pd.Timestamp('2015-12-29'))\n",
    "plt.ylabel('Number of New Cases')\n",
    "plt.title('New Ebola Cases Over Time')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# new cases each day does not represent the number of currently infectious individuals I(t)\n",
    "# Using the convert_cumulative_to_SIR function to approximate S(t), I(t), and R(t) from the data\n",
    "population = 7092113  # Sierra Leone 2015 population according to 2015 census\n",
    "data_sir = convert_cumulative_to_SIR(\n",
    "    data,\n",
    "    date_col='date',\n",
    "    cumulative_col='confirmed_cases',\n",
    "    population=population,\n",
    "    infectious_period=14, # consistent with Ebola\n",
    "    new_case_col='new_cases',\n",
    "    I_col='I_est',\n",
    "    R_col='R_est',\n",
    "    S_col='S_est')\n",
    "\n",
    "# Plot the Infectious population over time for first year after shutdown\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(data_sir['date'],\n",
    "         data_sir['I_est'],\n",
    "         label='Infectious (I)',\n",
    "         color='red')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.xlim(pd.Timestamp('2014-08-29'), pd.Timestamp('2015-12-29'))\n",
    "plt.ylim(0, 6e3)\n",
    "plt.ylabel('Number of Individuals')\n",
    "plt.title('Estimated Infections of Ebola in Sierra Leone')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the SIR estimates over time\n",
    "# Since infected and recovered are small fractions of the population, susceptible population only decreases from 7,092,113 to ~7,078,000\n",
    "# This interferes with scale of graph, so only I and R are plotted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_sir['date'],\n",
    "         data_sir['I_est'],\n",
    "         label='Infectious (I)',\n",
    "         color='red')\n",
    "plt.plot(data_sir['date'],\n",
    "         data_sir['R_est'],\n",
    "         label='Recovered (R)',\n",
    "         color='green')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Percent of Individuals')\n",
    "plt.title('Approximated SIR Populations of Ebola in Sierra Leone')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45438770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Euler's method for SIR model (not working when pulled from main_functions.py)\n",
    "\n",
    "def euler_sir(beta, gamma, S0, I0, R0, t, N):\n",
    "    \"\"\"\n",
    "    Solve the SIR model using Euler's method.\n",
    "    Parameters:\n",
    "    - beta: Infection rate\n",
    "    - gamma: Recovery rate\n",
    "    - S0: Initial susceptible population\n",
    "    - I0: Initial infected population\n",
    "    - R0: Initial recovered population\n",
    "    - t: Array of time points (days or weeks)\n",
    "    - N: Total population\n",
    "    Returns:\n",
    "    - S: Array of susceptible population over time\n",
    "    - I: Array of infected population over time\n",
    "    - R: Array of recovered population over time\n",
    "    \"\"\"\n",
    "    S = np.zeros(len(t))\n",
    "    I = np.zeros(len(t))\n",
    "    R = np.zeros(len(t))\n",
    "    S[0], I[0], R[0] = S0, I0, R0\n",
    "    for n in range(len(t) - 1):\n",
    "        dt = t[n + 1] - t[n]  # dt is our step size (1 day or 1 week)\n",
    "        dS = -(beta/N)*I[n]*S[n]  # FILL IN BASED ON SIR MODEL\n",
    "        dI = (beta/N)*I[n]*S[n] - (gamma*I[n])  # FILL IN BASED ON SIR MODEL\n",
    "        dR = gamma*I[n]  # FILL IN BASED ON SIR MODEL\n",
    "        S[n + 1] = S[n] + dS*dt  # FILL IN BASED ON EULER'S METHOD\n",
    "        I[n + 1] = I[n] + dI*dt  # FILL IN BASED ON EULER'S METHOD\n",
    "        R[n + 1] = R[n] + dR*dt  # FILL IN BASED ON EULER'S METHOD\n",
    "    return S, I, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c42543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the euler_SIR function defined earlier, plug in guesses for gamma and beta, \n",
    "# plot the model predictions against the data, and calculate SSE.\n",
    "\n",
    "I_obs = data_sir['I_est'].values.astype(float)   # Set up I_obs array from data directly\n",
    "t_obs = np.linspace(0, len(I_obs)-1, len(I_obs)) # time array in days\n",
    "\n",
    "I0_obs = data_sir.iloc[0]['I_est']\n",
    "R0_obs = 0.0\n",
    "S0_obs = population - I0_obs - R0_obs\n",
    "\n",
    "beta1 = 3.1 #random guess for beta\n",
    "gamma1 = 3 #random guess for gamma\n",
    "beta2 = .5 #random guess for beta\n",
    "gamma2 = .48 #random guess for gamma\n",
    "S1,I1,R1 = euler_sir(beta1, gamma1,S0_obs, I0_obs, R0_obs, t_obs, population)\n",
    "S2,I2,R2 = euler_sir(beta2, gamma2,S0_obs, I0_obs, R0_obs, t_obs, population)\n",
    "sse1 = np.sum((I1 - I_obs)**2)\n",
    "sse2 = np.sum((I2 - I_obs)**2)\n",
    "\n",
    "plt.plot(t_obs, I1, label=f'beta={beta1},gamma={gamma1}', marker='x')\n",
    "plt.plot(t_obs, I2, label=f'beta={beta2},gamma={gamma2}', marker='x')\n",
    "plt.plot(t_obs, I_obs,'o', label='Observed')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('days')\n",
    "plt.ylabel('Infections')\n",
    "plt.title('Demo: effect of beta/gamma on I(t)')\n",
    "plt.show()\n",
    "\n",
    "print(sse1)\n",
    "print(sse2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6277deb",
   "metadata": {},
   "source": [
    "By randomly guessing beta and gamma values, we found the bets gamma and beta values were around 3 with a R0 value (beta/gamma) of about \n",
    "1.03-1.04. We used these guesses to inform a range for a gridsearch optimization routine to minimize SSE. This performed better than the scipy minimize function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25695979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an optimization routine to minimize SSE and find the best-fitting parameters.\n",
    "best_sse = float('inf')\n",
    "best_beta = None\n",
    "best_gamma = None\n",
    "for j in range(100):\n",
    "    beta_guess = np.random.uniform(2.8, 3.2)\n",
    "    for k in range(100):\n",
    "        gamma_guess = np.random.uniform(2.8, 3.2)\n",
    "        S, I, R = euler_sir(beta_guess, gamma_guess, S0_obs, I0_obs, R0_obs, t_obs, population)\n",
    "        sse = np.sum((I - I_obs)**2)\n",
    "        if sse < best_sse:\n",
    "            best_sse = sse\n",
    "            best_beta = beta_guess\n",
    "            best_gamma = gamma_guess\n",
    "            print(f\"New best SSE: {best_sse} with beta={best_beta}, gamma={best_gamma}\")\n",
    "\n",
    "print(f\"GRIDSEARCH OPTIMIZED RESULTS:\")\n",
    "print(f\"Beta: {best_beta:.4f}\")\n",
    "print(f\"Gamma: {best_gamma:.4f}\")\n",
    "print(f\"SSE: {best_sse:,.0f}\")\n",
    "\n",
    "# Plot the best-fitting model against the observed data\n",
    "S_best, I_best, R_best = euler_sir(best_beta, best_gamma, S0_obs, I0_obs, R0_obs, t_obs, population)\n",
    "plt.plot(t_obs, I_best, label=f'Best fit: beta={best_beta:.2f}, gamma={best_gamma:.2f}', marker='x')\n",
    "plt.plot(t_obs, I_obs, 'o', label='Observed')\n",
    "plt.legend()\n",
    "plt.xlabel('days')\n",
    "plt.ylabel('Infections')\n",
    "plt.title('Best Fit SIR Model to Ebola Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e421c9",
   "metadata": {},
   "source": [
    "#### 2. Predict \"the future\" with your fit SIR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the euler_SIR function defined earlier, plug in guesses for gamma and beta, \n",
    "# plot the model predictions against the data, and calculate SSE.\n",
    "\n",
    "I_obs = data_sir['I_est'].values.astype(float)   # Set up I_obs array from data directly\n",
    "t_obs = np.linspace(0, len(I_obs)-1, len(I_obs)) # time array in days\n",
    "\n",
    "I0_obs = data_sir.iloc[0]['I_est']\n",
    "R0_obs = 0.0\n",
    "S0_obs = population - I0_obs - R0_obs\n",
    "\n",
    "# NEW: Split data into first half and second half\n",
    "split_idx = len(I_obs) // 2\n",
    "I_obs_first_half = I_obs[:split_idx]\n",
    "t_obs_first_half = t_obs[:split_idx]\n",
    "\n",
    "print(f\"Training on first {split_idx} days, testing on remaining {len(I_obs) - split_idx} days\\n\")\n",
    "\n",
    "# Use grid search on first half only\n",
    "best_sse = float('inf')\n",
    "best_beta = None\n",
    "best_gamma = None\n",
    "for j in range(100):\n",
    "    beta_guess = np.random.uniform(2.5, 3.5) # slightly wider range\n",
    "    for k in range(100):\n",
    "        gamma_guess = np.random.uniform(2.5, 3.5)\n",
    "        # Simulate only first half\n",
    "        S, I, R = euler_sir(beta_guess, gamma_guess, S0_obs, I0_obs, R0_obs, t_obs_first_half, population)\n",
    "        # Calculate SSE on first half only\n",
    "        sse = np.sum((I - I_obs_first_half)**2)\n",
    "        if sse < best_sse:\n",
    "            best_sse = sse\n",
    "            best_beta = beta_guess\n",
    "            best_gamma = gamma_guess\n",
    "            print(f\"New best SSE: {best_sse:.2f} with beta={best_beta:.4f}, gamma={best_gamma:.4f}\")\n",
    "\n",
    "print(f\"\\nGRIDSEARCH OPTIMIZED RESULTS (First Half Only):\")\n",
    "print(f\"Beta: {best_beta:.4f}\")\n",
    "print(f\"Gamma: {best_gamma:.4f}\")\n",
    "print(f\"SSE (first half): {best_sse:,.0f}\")\n",
    "\n",
    "# Plot the best-fitting model with train/test split shown (formatted with Claude)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(t_obs[:split_idx], I_obs[:split_idx], 'o', label='Observed (Training)', color='blue', markersize=6)\n",
    "plt.plot(t_obs[split_idx:], I_obs[split_idx:], 's', label='Observed (Testing)', color='green', markersize=6)\n",
    "plt.plot(t_obs[:split_idx], I_best[:split_idx], '-', label='Model Fit (Training)', color='red', linewidth=2.5)\n",
    "plt.plot(t_obs[split_idx:], I_best[split_idx:], '--', label='Model Prediction (Testing)', color='orange', linewidth=2.5)\n",
    "plt.axvline(x=t_obs[split_idx], color='black', linestyle=':', linewidth=2, label=f'Split (day {split_idx})')\n",
    "plt.legend()\n",
    "plt.xlabel('days')\n",
    "plt.ylabel('Infections (in millions)')\n",
    "plt.title(f'Train on First Half, Predict Second Half (β={best_beta:.3f}, γ={best_gamma:.3f})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "type(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae04c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating SSE between model predictions and data on the SECOND HALF of the data.\n",
    "\n",
    "S_best, I_best, R_best = euler_sir(best_beta, best_gamma, S0_obs, I0_obs, R0_obs, t_obs, population)\n",
    "\n",
    "# Calculate SSE for both halves\n",
    "sse_first = np.sum((I_best[:split_idx] - I_obs[:split_idx])**2)\n",
    "sse_second = np.sum((I_best[split_idx:] - I_obs[split_idx:])**2)\n",
    "sse_total = np.sum((I_best - I_obs)**2)\n",
    "\n",
    "# Printing formatted by Claude\n",
    "print(f\"\\nValidation:\")\n",
    "print(f\"  SSE (first half - training):  {sse_first:,.0f}\")\n",
    "print(f\"  SSE (second half - testing):  {sse_second:,.0f}\")\n",
    "print(f\"  SSE (total):                   {sse_total:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7637152",
   "metadata": {},
   "source": [
    "**Is the new gamma and beta close to what you found on the full dataset? Is the fit much worse? What is the SSE calculated for the second half of the data?**\n",
    "\n",
    "The beta and gamma are very close to the full data set, and the fit is actually a bit better. SSE of the second half: 3,996,868. Total SSE:\n",
    "22,263,843 (less than original optimization!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576347a8",
   "metadata": {},
   "source": [
    "**Describe how using a different method like the midpoint method might lower the numerical error.**\n",
    "\n",
    "As we talked about in class, Euler's method has first-order accuracy so error accumulates linearly with step size. The midpoint method has second-order accuracy so error accumulates at the square root of step size, resulting in a much smaller error. Using RK4 below, which has fourth-order accuracy, will significantly reduce the error (hopefully)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06864a71",
   "metadata": {},
   "source": [
    "#### 3. Decreasing numerical error with the RK4 Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1432c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# Define the SIR derivatives for solve_ivp\n",
    "def sir_derivatives(t, y, beta, gamma, N):\n",
    "    S, I, R = y\n",
    "    dS = -(beta/N) * I * S\n",
    "    dI = (beta/N) * I * S - (gamma * I)\n",
    "    dR = gamma * I\n",
    "    return [dS, dI, dR]\n",
    "\n",
    "# Wrapper function to match euler_sir interface\n",
    "def solve_ivp_sir(beta, gamma, S0, I0, R0, t, N):\n",
    "    y0 = [S0, I0, R0]\n",
    "    solution = solve_ivp(sir_derivatives, (t[0], t[-1]), y0, t_eval=t, \n",
    "                         args=(beta, gamma, N), method='RK45')\n",
    "    return solution.y[0], solution.y[1], solution.y[2]\n",
    "\n",
    "\n",
    "# Plug in guesses for gamma and beta, plot the model predictions against the data, and calculate SSE.\n",
    "\n",
    "I_obs = data_sir['I_est'].values.astype(float)   # Set up I_obs array from data directly\n",
    "t_obs = np.linspace(0, len(I_obs)-1, len(I_obs)) # time array in days\n",
    "\n",
    "I0_obs = data_sir.iloc[0]['I_est']\n",
    "R0_obs = 0.0\n",
    "S0_obs = population - I0_obs - R0_obs\n",
    "\n",
    "# NEW: Split data into first half and second half\n",
    "split_idx = len(I_obs) // 2\n",
    "I_obs_first_half = I_obs[:split_idx]\n",
    "t_obs_first_half = t_obs[:split_idx]\n",
    "\n",
    "print(f\"Training on first {split_idx} days, testing on remaining {len(I_obs) - split_idx} days\\n\")\n",
    "\n",
    "# Use grid search on first half only\n",
    "best_sse = float('inf')\n",
    "best_beta = None\n",
    "best_gamma = None\n",
    "for j in range(100):\n",
    "    beta_guess = np.random.uniform(2.5, 3.5) # slightly wider range\n",
    "    for k in range(100):\n",
    "        gamma_guess = np.random.uniform(2.5, 3.5)\n",
    "        # CHANGED: euler_sir -> solve_ivp_sir\n",
    "        S, I, R = solve_ivp_sir(beta_guess, gamma_guess, S0_obs, I0_obs, R0_obs, t_obs_first_half, population)\n",
    "        # Calculate SSE on first half only\n",
    "        sse = np.sum((I - I_obs_first_half)**2)\n",
    "        if sse < best_sse:\n",
    "            best_sse = sse\n",
    "            best_beta = beta_guess\n",
    "            best_gamma = gamma_guess\n",
    "            print(f\"New best SSE: {best_sse:.2f} with beta={best_beta:.4f}, gamma={best_gamma:.4f}\")\n",
    "\n",
    "print(f\"\\nGRIDSEARCH OPTIMIZED RESULTS (First Half Only):\")\n",
    "print(f\"Beta: {best_beta:.4f}\")\n",
    "print(f\"Gamma: {best_gamma:.4f}\")\n",
    "print(f\"SSE (first half): {best_sse:,.0f}\")\n",
    "\n",
    "# CHANGED: euler_sir -> solve_ivp_sir\n",
    "S_best, I_best, R_best = solve_ivp_sir(best_beta, best_gamma, S0_obs, I0_obs, R0_obs, t_obs, population)\n",
    "\n",
    "# Calculate SSE for both halves\n",
    "sse_first = np.sum((I_best[:split_idx] - I_obs[:split_idx])**2)\n",
    "sse_second = np.sum((I_best[split_idx:] - I_obs[split_idx:])**2)\n",
    "sse_RK4 = np.sum((I_best - I_obs)**2)\n",
    "\n",
    "# Plot the best-fitting model with train/test split shown (formatted with Claude)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(t_obs[:split_idx], I_obs[:split_idx], 'o', label='Observed (Training)', color='blue', markersize=6)\n",
    "plt.plot(t_obs[split_idx:], I_obs[split_idx:], 's', label='Observed (Testing)', color='green', markersize=6)\n",
    "plt.plot(t_obs[:split_idx], I_best[:split_idx], '-', label='Model Fit (Training)', color='red', linewidth=2.5)\n",
    "plt.plot(t_obs[split_idx:], I_best[split_idx:], '--', label='Model Prediction (Testing)', color='orange', linewidth=2.5)\n",
    "plt.axvline(x=t_obs[split_idx], color='black', linestyle=':', linewidth=2, label=f'Split (day {split_idx})')\n",
    "plt.legend()\n",
    "plt.xlabel('days')\n",
    "plt.ylabel('Infections (in millions)')\n",
    "plt.title(f'Train on First Half, Predict Second Half (RK4) (β={best_beta:.3f}, γ={best_gamma:.3f})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b9d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating SSE between model predictions and data on the SECOND HALF of the data.\n",
    "print(f\"\\nValidation:\")\n",
    "print(f\"  SSE (first half - training):  {sse_first:,.0f}\")\n",
    "print(f\"  SSE (second half - testing):  {sse_second:,.0f}\")\n",
    "print(f\"  SSE (total):                   {sse_RK4:,.0f}\")\n",
    "\n",
    "print(\"SSE (Euler):\", sse_total)\n",
    "print(\"SSE (RK4):\", sse_RK4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ea1779",
   "metadata": {},
   "source": [
    "**Compare the SSE for the SECOND HALF of the data when the model is fit to the FIRST HALF of the data using Euler's method vs RK4. Did RK4 do a better job?  Why or why not?**\n",
    "\n",
    "RK4 did not do a better job, surprisingly. This is pretty counterintuitive, but one reason may be that it the error in our SIR model lend themselves to the errors in Euler's method, making it a good fit for the data. RK4, while more accurate in most situations, does not fit the data well because its errors are different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f3b391",
   "metadata": {},
   "source": [
    "#### 4. Improving model fit by overcoming model limitations\n",
    "\n",
    "Originially, we chose adding an E group to make an SEIR model, but we could not get this to improve our original model. We pivoted to another option, a time-dependent beta. This data follows a very strange curve, and our constant beta can't hit top of the peak AND not speed down to zero right afterward. Having a higher beta in the beginning and a lower one after the spike could benefit our model greatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA (keeping your original preprocessing)\n",
    "# ============================================================================\n",
    "\n",
    "data = pd.read_csv(r\"ebola_sierra_leone_data_2014_2015_cumulative.csv\")\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data = data.sort_values('date').reset_index(drop=True)\n",
    "data['new_cases'] = data['confirmed_cases'].diff().fillna(0)\n",
    "\n",
    "population = 7092113\n",
    "infectious_period = 14\n",
    "\n",
    "data_sir = convert_cumulative_to_SIR(  # Back to SIR!\n",
    "    data,\n",
    "    date_col='date',\n",
    "    cumulative_col='confirmed_cases',\n",
    "    population=population,\n",
    "    infectious_period=infectious_period,\n",
    "    new_case_col='new_cases',\n",
    "    I_col='I_est',\n",
    "    R_col='R_est',\n",
    "    S_col='S_est')\n",
    "\n",
    "# ============================================================================\n",
    "# SIR TIME-VARYING BETA MODEL\n",
    "# ============================================================================\n",
    "\n",
    "def sir_derivatives_time_varying(t, y, beta_early, beta_late, transition_day, transition_width, gamma, N):\n",
    "    \"\"\"SIR with time-varying beta - simpler than SEIR!\"\"\"\n",
    "    S, I, R = y\n",
    "    \n",
    "    # Smooth transition\n",
    "    transition = 1 / (1 + np.exp(-(t - transition_day) / transition_width))\n",
    "    beta = beta_early * (1 - transition) + beta_late * transition\n",
    "    \n",
    "    dS = -(beta/N) * I * S\n",
    "    dI = (beta/N) * I * S - gamma * I\n",
    "    dR = gamma * I\n",
    "    \n",
    "    return [dS, dI, dR]\n",
    "\n",
    "def solve_sir_time_varying(beta_early, beta_late, transition_day, transition_width, gamma, S0, I0, R0, t, N):\n",
    "    \"\"\"Solve SIR with time-varying beta\"\"\"\n",
    "    y0 = [S0, I0, R0]\n",
    "    solution = solve_ivp(\n",
    "        sir_derivatives_time_varying,\n",
    "        (t[0], t[-1]),\n",
    "        y0,\n",
    "        t_eval=t,\n",
    "        args=(beta_early, beta_late, transition_day, transition_width, gamma, N),\n",
    "        method='RK45'\n",
    "    )\n",
    "    return solution.y[0], solution.y[1], solution.y[2]\n",
    "\n",
    "def solve_sir_constant(beta, gamma, S0, I0, R0, t, N):\n",
    "    \"\"\"Solve SIR with constant beta (your original working model)\"\"\"\n",
    "    def sir_derivatives(t, y, beta, gamma, N):\n",
    "        S, I, R = y\n",
    "        dS = -(beta/N) * I * S\n",
    "        dI = (beta/N) * I * S - gamma * I\n",
    "        dR = gamma * I\n",
    "        return [dS, dI, dR]\n",
    "    \n",
    "    y0 = [S0, I0, R0]\n",
    "    solution = solve_ivp(sir_derivatives, (t[0], t[-1]), y0, t_eval=t,\n",
    "                         args=(beta, gamma, N), method='RK45')\n",
    "    return solution.y[0], solution.y[1], solution.y[2]\n",
    "\n",
    "# ============================================================================\n",
    "# SETUP\n",
    "# ============================================================================\n",
    "\n",
    "I_obs = data_sir['I_est'].values.astype(float)\n",
    "t_obs = np.linspace(0, len(I_obs)-1, len(I_obs))\n",
    "\n",
    "I0_obs = data_sir.iloc[0]['I_est']\n",
    "R0_obs = 0.0\n",
    "S0_obs = population - I0_obs - R0_obs\n",
    "\n",
    "# ============================================================================\n",
    "# OPTIMIZATION - 2 MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARING THREE SIR MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Model 1: Your original constant beta (2 parameters)\n",
    "print(\"\\n1. Optimizing CONSTANT BETA (your original approach)...\")\n",
    "\n",
    "def sse_constant(params):\n",
    "    beta, gamma = params\n",
    "    S, I, R = solve_sir_constant(beta, gamma, S0_obs, I0_obs, R0_obs, t_obs, population)\n",
    "    return np.sum((I - I_obs)**2)\n",
    "\n",
    "result_const = minimize(sse_constant, [3, 3], method='L-BFGS-B',\n",
    "                        bounds=[(2.5, 3.5), (2.5, 3.5)])\n",
    "beta_const, gamma_const = result_const.x\n",
    "sse_const = result_const.fun\n",
    "\n",
    "print(f\"   Beta:  {beta_const:.4f}\")\n",
    "print(f\"   Gamma: {gamma_const:.4f}\")\n",
    "print(f\"   SSE:   {sse_const:,.0f}\")\n",
    "\n",
    "# Model 2: Time-varying beta (3 parameters - fix transition_width)\n",
    "print(\"\\n2. Optimizing TIME-VARYING BETA (fixed transition width)...\")\n",
    "\n",
    "def sse_time_varying(params):\n",
    "    beta_early, beta_late, transition_day, gamma = params\n",
    "    S, I, R = solve_sir_time_varying(beta_early, beta_late, transition_day, 10.0, gamma,\n",
    "                                       S0_obs, I0_obs, R0_obs, t_obs, population)\n",
    "    return np.sum((I - I_obs)**2)\n",
    "\n",
    "result_tv = minimize(sse_time_varying, [6.0, 2.0, 30.0, 0.3], method='L-BFGS-B',\n",
    "                     bounds=[(1.0, 20.0), (0.1, 10.0), (10, 80), (0.01, 2.0)])\n",
    "beta_early, beta_late, trans_day, gamma_tv = result_tv.x\n",
    "sse_tv = result_tv.fun\n",
    "\n",
    "print(f\"   Beta (early): {beta_early:.4f}\")\n",
    "print(f\"   Beta (late):  {beta_late:.4f}\")\n",
    "print(f\"   Transition:   Day {trans_day:.1f}\")\n",
    "print(f\"   Gamma:        {gamma_tv:.4f}\")\n",
    "print(f\"   SSE:          {sse_tv:,.0f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS:\")\n",
    "print(f\"   Constant beta SSE:      {sse_const:,.0f}\")\n",
    "print(f\"   Time-varying beta SSE:  {sse_tv:,.0f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SOLVE AND PLOT\n",
    "# ============================================================================\n",
    "\n",
    "S_const, I_const, R_const = solve_sir_constant(beta_const, gamma_const, S0_obs, I0_obs, R0_obs, t_obs, population)\n",
    "S_tv, I_tv, R_tv = solve_sir_time_varying(beta_early, beta_late, trans_day, 10.0, gamma_tv,\n",
    "                                            S0_obs, I0_obs, R0_obs, t_obs, population)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Model fits\n",
    "axes[0, 0].plot(t_obs, I_obs, 'o', label='Observed', alpha=0.7, markersize=4, color='black')\n",
    "axes[0, 0].plot(t_obs, I_const, '-', label='Constant β', linewidth=2.5, color='blue')\n",
    "axes[0, 0].set_xlabel('Days')\n",
    "axes[0, 0].set_ylabel('Infectious')\n",
    "axes[0, 0].set_title(f'Constant Beta\\nSSE={sse_const:,.0f}')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(t_obs, I_obs, 'o', label='Observed', alpha=0.7, markersize=4, color='black')\n",
    "axes[0, 1].plot(t_obs, I_tv, '-', label='Time-varying β', linewidth=2.5, color='red')\n",
    "axes[0, 1].axvline(x=trans_day, color='gray', linestyle='--', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Days')\n",
    "axes[0, 1].set_ylabel('Infectious')\n",
    "axes[0, 1].set_title(f'Time-Varying Beta\\nSSE={sse_tv:,.0f}')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "res_const = I_const - I_obs\n",
    "res_tv = I_tv - I_obs\n",
    "\n",
    "axes[1, 0].plot(t_obs, res_const, 'o-', markersize=3, color='blue')\n",
    "axes[1, 0].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[1, 0].set_xlabel('Days')\n",
    "axes[1, 0].set_ylabel('Residual')\n",
    "axes[1, 0].set_title('Residuals: Constant Beta')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(t_obs, res_tv, 'o-', markersize=3, color='red')\n",
    "axes[1, 1].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[1, 1].axvline(x=trans_day, color='gray', linestyle='--', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('Days')\n",
    "axes[1, 1].set_ylabel('Residual')\n",
    "axes[1, 1].set_title('Residuals: Time-Varying Beta')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a58b500",
   "metadata": {},
   "source": [
    "As you can see, our original model with a constant beta still fits the data better. Sometimes, simpler is better. The new model seems to do slightly better after the spike with a less harsh downslope, but it underperforms at the spike, where errors are \"weighted\" higher, so it's overall SSE is worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c67b6a4-ec94-4d28-b2a7-f6b860495118",
   "metadata": {},
   "source": [
    "## Verify and validate your analysis: \n",
    "\n",
    "To verify our analysis, we performed multiple internal consistency checks using both numerical methods and model variants. We implemented and compared Euler’s method and RK4 solver for the SIR model and found that Euler’s method produced a better fit to the observed infection data, as measured by the sum of squared errors (SSE). This consistency across numerical approaches increased confidence that the observed trends were driven by model structure and parameter choices rather than numerical artifacts. We also verified our optimization procedure by comparing parameter estimation via grid search and scipy.optimize, finding that grid search consistently produced lower SSE values, suggesting a more reliable global minimum for this dataset. To validate our findings, we compared our model behavior to established epidemiological literature on Ebola outbreaks (https://pmc.ncbi.nlm.nih.gov/articles/PMC12441668/). Prior studies have shown that simple SIR models often outperform more complex SEIR models for Ebola due to short incubation periods and limited high-resolution data during outbreaks. Additionally, literature supports the idea that assuming a constant transmission rate (β) can outperform time-varying β models when data are sparse or noisy, as over-parameterization can reduce predictive accuracy. The fact that our constant-β SIR model produced the lowest SSE and best spike alignment is consistent with these findings, suggesting that our results are supported by external epidemiological evidence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2736cf95-2b93-444f-90c8-d40a54fc1df1",
   "metadata": {},
   "source": [
    "## Conclusions and Ethical Implications: \n",
    "Our analysis suggests that, for the Ebola outbreak data examined, a relatively simple SIR model with a constant transmission rate provides the most reliable fit to observed infection dynamics. While more complex models, such as SEIR or time-dependent β variants, offer theoretical advantages, they did not improve predictive accuracy in practice and often underperformed during the peak of the outbreak. This reinforces the idea that model simplicity can be a strength when working with limited or uncertain real-world data. Ethically, these findings highlight the responsibility modelers have when informing public health decisions. Overly complex models may give a false sense of precision, potentially misleading policymakers or the public during crises. Simpler, well-validated models may be more transparent, interpretable, and ethically appropriate when rapid decision-making is required. However, ethical care must be taken to clearly communicate uncertainty and avoid presenting model outputs as definitive predictions, particularly in high-stakes public health contexts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023b735-6efb-43ed-a03d-eb4a9cdb734e",
   "metadata": {},
   "source": [
    "## Limitations and Future Work: \n",
    "A primary limitation of this analysis is the quality and resolution of the available Ebola outbreak data. Underreporting, reporting delays, and aggregation effects likely influenced parameter estimation and model fit. Additionally, our models assume homogeneous mixing of the population and do not account for spatial effects, behavioral changes, or intervention measures such as quarantines or treatment centers.\n",
    "Future work could incorporate stochastic models and spatially structured compartments to better capture localized transmission dynamics. Incorporating external datasets, such as mobility data or intervention timelines, could also improve realism. Finally, exploring Bayesian parameter estimation would allow uncertainty to be explicitly quantified, improving both interpretability and ethical transparency when communicating results to decision-makers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9295960-2404-43dc-b46f-9a6f823f1657",
   "metadata": {},
   "source": [
    "## NOTES FROM YOUR TEAM: \n",
    "\n",
    "- Background on Ebola and dataset has been done.\n",
    "- Interesting history on outbreak!\n",
    "- Euler's optimization done\n",
    "- Euler's prediction done\n",
    "- Grid search found to be better than scipy minimize\n",
    "- RK4 implementation done, Euler's found to be better\n",
    "- SEIR model is not optimizing well\n",
    "- Implemented time-dependent beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd725b7f-9741-46b6-a213-9518da9201c3",
   "metadata": {},
   "source": [
    "## QUESTIONS FOR YOUR TA: \n",
    "Thank you for such an amazing semester!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
